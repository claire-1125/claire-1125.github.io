---
title: "[ 이론공부 ]  GAN part 1"
date: 2022-01-10
excerpt: "Minimax Algorithm와 GAN에 대해 알아봅시다."
categories: 
    - POSCO AI project
---


# Minimax Algorithm

## Background Knowledge

### Intelligent (Rational) Agent란 무엇인가?

![1.png](/assets/images/posts/POSCO_AI_project/gan1/1.png){: width="200"}

- agent가 하는 일
    - perceive its environment through sensor (주변 환경 인지)
    - act upon that environment through actuators (적절한 action 취함)


### ‘Rational’한 Agent

1. 충분한 양의 information을 gather해서
2. 1을 가지고 계속 학습해서 agent ftn.을 개선시킴으로써
3. 궁극적으로 performance measure를 maximize하도록 하는 agent
- agent는 omniscient (전지전능)하지 않다! (rationality ≠ perfection)
- agent는 performance measure를 **maximize할 것으로 예상되는** action을 취한다.


### 특성에 따른 task environment의 구분  

agent는 environment와의 상호작용을 통해 action을 취하므로 환경이 어떠한 특성을 지녔는지 파악하는 것은 매우 중요하다.

- 현재 상황 : **‘competitive’ ‘multi’**-agent
    
    본인의 performance를 maximize시키도록 **상대방의 performance를 minimize**시키는 방식
    
    c.f.) 용어 설명
    
    - multi-agent : agent가 여러 개인 상황 e.g.) adversarial search
    - competitive multi-agent : zero-sum
    - cooperative multi-agent : 서로 협력
    


# Minimax Algorithm

![2.png](/assets/images/posts/POSCO_AI_project/gan1/2.png){: width="200"}

MAX 기준으로 tree 그림 (MAX 이기는 경우에 utility가 +1)

### 필요한 요소
- $s_0$ : initial state
- PLAYER(s) : 현재 state에서 action 취할 수 있는 사람 i.e.) MAX or MIN
- ACTIONS(s) : 현재 state에서 가능한 action들
- RESULT(s,a) : state에서 action 취한 결과
- TERMINAL_TEST(s) : 지금 state가 terminal (게임 끝)인가?
- UTILITY(s,p) : state $s$, player $p$일 때 utility ftn.값.
    - 이기면 +1, 지면 0, 비기면 +1/2


### Optimal Decisions in Games : Minimax Algo.
    - optimal decision : 상대방이 (그 선택권 안에서) 최선의 선택을 한다고 가정
        ![3.jpg](/assets/images/posts/POSCO_AI_project/gan1/3.jpg){: width="200"}
    




# GAN ( generative adversarial networks )

## GAN이란 무엇인가?

- minimax algo.에 기반을 두고 있다.

![4.png](/assets/images/posts/POSCO_AI_project/gan1/4.png){: width="200"}

1. 제일 처음 **Noise**가 있다. 해당 Noise는 위 수식에서 **z**라고 표현된다.

2. 해당 noise를 가지고 Generator(위조지폐범이) 위조지폐를 만든다. 만들어진 위조지폐들을 위 수식에서 **G(z)**라고 하자.

3. 이제 Discriminator(경찰) 이 위조지폐와 실제 지폐를 구분해야 한다. 경찰은 이게 위조지폐라면 0을 출력하고, 진짜 지폐라면 1을 출력하기로 한다. 위조지폐 G(z) 와 실제 지폐 x 가 경찰 손으로 들어갔을 때, D(G(z))는 위조지폐이기 때문에 0, 실제 지폐는 D(x)는 1을 출력하게 된다.

이렇게 **한번 경찰이 해당 지폐들을 구분한 게 한 번의 epoch** 가 된다. 첫 번째 도전에서 경찰이 위조지폐와 진짜 지폐를 잘 구분할지라도, 점차 위조 지폐 범은 더욱 비슷하게 생긴 위조지폐를 만들려고 노력할 것이고 경찰도 점차 위조지폐를 더 잘 구분하기 위해 노력할 것이다. 그러다가 어느 순간 너무나도 완벽한 위조지폐가 탄생한다면, 경찰은 결국 해당 지폐를 구분하지 못하기 때문에 이게 진짜인지 가짜인지 찍기 시작할 것이다. 확률은 둘 중 하나일 테니 결국 **50%로 가 될 것이고, 그 순간 학습이 끝나게 된다.**


# Generator와 Discriminator

## Generator
![5.jpg](/assets/images/posts/POSCO_AI_project/gan1/5.jpg){: width="200"}

- Unsupervised Learning
- MLP (multilayer perceptron)
- 어떤 latent code를 가지고 training 데이터가 되도록 학습하는 과정을 말한다.
- **실제 데이터의 확률 분포와 유사한 모델**을 제작하려 한다.
- **D(G(z))가 1에 가까워지도록** 하는 게 목표


## Discriminator

- Supervised Learning
- MLP (multilayer perceptron)
- 어떠한 input 데이터가 들어갔을 때, 해당 input 값이 어떤 것인지 **Classify** 한다. = **output이 0 혹은 1**
- classify할 때 **sigmoid function**을 이용한다.

    ![6.jpg](/assets/images/posts/POSCO_AI_project/gan1/6.jpg){: width="200"}
